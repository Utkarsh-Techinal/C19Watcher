{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Social_distancing_V2.ipynb",
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcuaa9wm_Zrr"
      },
      "source": [
        "# install dependencies: \n",
        "!pip install pyyaml==5.1 pycocotools>=2.0.1\n",
        "import torch, torchvision\n",
        "print(torch.__version__, torch.cuda.is_available())\n",
        "!gcc --version\n",
        "# opencv is pre-installed on colab\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOsfuhwc_glX"
      },
      "source": [
        "# install detectron2: (Colab has CUDA 10.1 + torch 1.6)\n",
        "# See https://detectron2.readthedocs.io/tutorials/install.html for instructions\n",
        "assert torch.__version__.startswith(\"1.6\")\n",
        "!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.6/index.html"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olrz6Jfq_lC1"
      },
      "source": [
        "# Some basic setup:\n",
        "# Setup detectron2 logger\n",
        "import detectron2\n",
        "from detectron2.utils.logger import setup_logger\n",
        "setup_logger()\n",
        "\n",
        "# import some common libraries\n",
        "import numpy as np\n",
        "import os, json, cv2, random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog, DatasetCatalog"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qF_f9Ba6_0Wq"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jB8IgdydAEIK"
      },
      "source": [
        "%%time\n",
        "!rm -r frames/*\n",
        "!mkdir frames/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRLwkJceCrtl"
      },
      "source": [
        "!cd frames"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPKYdZKRC4NP"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJqEZhCCC54j"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2wDpntWUDAky"
      },
      "source": [
        "\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJjQ0IIWDHB4"
      },
      "source": [
        "video = \"/content/sample.mp4\"\n",
        "\n",
        "cap = cv2.VideoCapture(video)\n",
        "cnt = 0\n",
        "\n",
        "if(cap.isOpened() == False):\n",
        "  print(\"Error opening video stream or file\")\n",
        "\n",
        "ret,first_frame = cap.read()\n",
        "\n",
        "while(cap.isOpened()):\n",
        "  ret,frame = cap.read()\n",
        "  if(ret == True):\n",
        "    cv2.imwrite('frames/'+str(cnt)+'.png',frame)\n",
        "    cnt = cnt + 1\n",
        "    if(cnt == 750):\n",
        "      break\n",
        "  else:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbAgy02EEgN4"
      },
      "source": [
        "FPS = cap.get(cv2.CAP_PROP_FPS)\n",
        "print(FPS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FV9-0KLoE98D"
      },
      "source": [
        "cfg = get_cfg()\n",
        "\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\"))\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.9\n",
        "\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Detection/faster_rcnn_R_50_C4_3x.yaml\")\n",
        "predictor = DefaultPredictor(cfg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3-g8ksbFuRC"
      },
      "source": [
        "img = cv2.imread(\"frames/30.png\")\n",
        "\n",
        "outputs = predictor(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tskiggI1GAf_"
      },
      "source": [
        "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
        "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
        "cv2_imshow(v.get_image()[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSTW7s4vGKO3"
      },
      "source": [
        "classes = outputs['instances'].pred_classes.cpu().numpy()\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCfnBuxIGx3V"
      },
      "source": [
        "bbox = outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "print(bbox)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLsriB6cHB6t"
      },
      "source": [
        "ind = np.where(classes == 0)[0]\n",
        "\n",
        "person = bbox[ind]#bbox of only people\n",
        "\n",
        "num = len(person)#total no of people in a single frame"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWmeJM42HTZb"
      },
      "source": [
        "#bbox format\n",
        "\n",
        "x1,y1,x2,y2 = person[0]\n",
        "print(x1,y1,x2,y2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvXFsYlZHocr"
      },
      "source": [
        "img = cv2.imread('frames/30.png')\n",
        "_=cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v0fExeaI-R-"
      },
      "source": [
        "#compute center\n",
        "\n",
        "x_center = int((x1+x2)/2)\n",
        "y_center = int(y2)\n",
        "\n",
        "center = (x_center, y_center)\n",
        "\n",
        "_ = cv2.circle(img, center, 5, (255, 0, 0), -1)\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Zji-utCJdnp"
      },
      "source": [
        "def mid_point(img,person,idx):\n",
        "  x1,y1,x2,y2 = person[idx]\n",
        "  _=cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
        "\n",
        "  x_mid = int((x1+x2)/2)\n",
        "  y_mid = int(y2)\n",
        "  mid = (x_mid, y_mid)\n",
        "\n",
        "  _=cv2.circle(img,mid,5,(0,255,0),-1)\n",
        "  cv2.putText(img, str(idx), mid, cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255),2,cv2.LINE_AA)\n",
        "\n",
        "  return mid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSxer6cRLj6H"
      },
      "source": [
        "midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9P2uIpm3L0-8"
      },
      "source": [
        "%%time\n",
        "from scipy.spatial import distance\n",
        "def compute_distance(midpoints,num):\n",
        "  dist = np.zeros((num,num))\n",
        "  for i in range(num):\n",
        "    for j in range(i+1, num):\n",
        "      if i!=j:\n",
        "        dst = distance.euclidean(midpoints[i], midpoints[j])\n",
        "        dist[i][j] = dst\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvMJ2XDNNrp2"
      },
      "source": [
        "dist = compute_distance(midpoints,num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-oijewyNylb"
      },
      "source": [
        "def find_closest(dist,num,thresh):\n",
        "  p1 = []\n",
        "  p2 = []\n",
        "  d = []\n",
        "  for i in range(num):\n",
        "    for j in range(i,num):\n",
        "      if((i!=j) & (dist[i][j] <= thresh)):\n",
        "        p1.append(i)\n",
        "        p2.append(j)\n",
        "        d.append(dist[i][j])\n",
        "  return p1,p2,d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJOfQTxmP0lc"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "thresh = 100\n",
        "p1,p2,d = find_closest(dist,num,thresh)\n",
        "df = pd.DataFrame({\"p1\":p1,\"p2\":p2,\"dist\":d})\n",
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b88Ss8EYQN9e"
      },
      "source": [
        "def change_2_red(img,person,p1,p2):\n",
        "  risky = np.unique(p1+p2)\n",
        "  for i in risky:\n",
        "    x1,y1,x2,y2 = person[i]\n",
        "    _ = cv2.rectangle(img,(x1,y1),(x2,y2),(255,0,0),2)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecvKbuaJQy6G"
      },
      "source": [
        "img = change_2_red(img,person,p1,p2)\n",
        "\n",
        "plt.figure(figsize = (20,10))\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsZPES-FRFm_"
      },
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "names=os.listdir('frames/')\n",
        "names.sort(key=lambda f: int(re.sub('\\D', '', f)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcwhFai7RXw9"
      },
      "source": [
        "def find_closest_people(name,thresh):\n",
        "\n",
        "  img = cv2.imread('frames/'+name)\n",
        "  outputs = predictor(img)\n",
        "  classes=outputs['instances'].pred_classes.cpu().numpy()\n",
        "  bbox=outputs['instances'].pred_boxes.tensor.cpu().numpy()\n",
        "  ind = np.where(classes==0)[0]\n",
        "  person=bbox[ind]\n",
        "  midpoints = [mid_point(img,person,i) for i in range(len(person))]\n",
        "  num = len(midpoints)\n",
        "  dist= compute_distance(midpoints,num)\n",
        "  p1,p2,d=find_closest(dist,num,thresh)\n",
        "  img = change_2_red(img,person,p1,p2)\n",
        "  cv2.imwrite('frames/'+name,img)\n",
        "  return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He09YRqARr7W"
      },
      "source": [
        "from tqdm import tqdm\n",
        "thresh=100\n",
        "_ = [find_closest_people(names[i],thresh) for i in tqdm(range(len(names))) ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2UP7IWIRywJ"
      },
      "source": [
        "%%time\n",
        "frames = os.listdir('frames/')\n",
        "frames.sort(key=lambda f: int(re.sub('\\D', '', f)))\n",
        "\n",
        "frame_array=[]\n",
        "\n",
        "for i in range(len(frames)):\n",
        "    \n",
        "    #reading each files\n",
        "    img = cv2.imread('frames/'+frames[i])\n",
        "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    height, width, layers = img.shape\n",
        "    size = (width,height)\n",
        "    \n",
        "    #inserting the frames into an image array\n",
        "    frame_array.append(img)\n",
        "\n",
        "out = cv2.VideoWriter('sample_output.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
        " \n",
        "for i in range(len(frame_array)):\n",
        "    # writing to a image array\n",
        "    out.write(frame_array[i])\n",
        "out.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}